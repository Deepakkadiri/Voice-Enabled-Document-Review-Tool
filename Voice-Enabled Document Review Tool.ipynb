{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "poxAdYLOvPQP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "# !pip install transformers spacy gensim nltk google-cloud-language\n",
        "# !pip install --upgrade google-cloud-language\n",
        "# !pip install python-docx PyPDF2\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "# Import required libraries\n",
        "import os\n",
        "from google.colab import files\n",
        "from transformers import pipeline\n",
        "import spacy\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from nltk.tokenize import word_tokenize\n",
        "from google.cloud import language_v1\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Ensure required NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to dynamically upload and extract text\n",
        "def upload_and_extract_text():\n",
        "    print(\"Upload your document (PDF, DOCX, or TXT):\")\n",
        "    uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "\n",
        "    if file_path.endswith(\".txt\"):\n",
        "        with open(file_path, \"r\") as file:\n",
        "            text = file.read()\n",
        "    elif file_path.endswith(\".pdf\"):\n",
        "        from PyPDF2 import PdfReader\n",
        "        reader = PdfReader(file_path)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        from docx import Document\n",
        "        doc = Document(file_path)\n",
        "        text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Please upload a PDF, DOCX, or TXT file.\")\n",
        "\n",
        "    return text\n",
        "\n",
        "# Function to summarize text (handles long text via chunking)\n",
        "def summarize_text(text, max_token_limit=1024):\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    chunks = []\n",
        "\n",
        "    # Split text into manageable chunks\n",
        "    while len(text) > max_token_limit:\n",
        "        split_point = text.rfind(\" \", 0, max_token_limit)\n",
        "        chunks.append(text[:split_point])\n",
        "        text = text[split_point:]\n",
        "    chunks.append(text)  # Append the final chunk\n",
        "\n",
        "    # Summarize each chunk\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        # Adjust max_length based on input length\n",
        "        input_length = len(chunk.split())\n",
        "        max_length = min(input_length // 2, 150)\n",
        "        summary = summarizer(chunk, max_length=max_length, min_length=50, do_sample=False)\n",
        "        summaries.append(summary[0]['summary_text'])\n",
        "\n",
        "    # Combine all summaries\n",
        "    return \" \".join(summaries)\n",
        "\n",
        "# Function for Named Entity Recognition (NER) using spaCy\n",
        "def extract_entities(text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Function for topic modeling using Gensim\n",
        "def topic_modeling(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words(\"english\")]\n",
        "    dictionary = corpora.Dictionary([tokens])\n",
        "    corpus = [dictionary.doc2bow(tokens)]\n",
        "    lda_model = LdaModel(corpus, num_topics=1, id2word=dictionary, passes=10)\n",
        "    topics = lda_model.print_topics(num_words=5)\n",
        "    return topics\n",
        "\n",
        "# Function for sentiment analysis using Google Cloud Natural Language API\n",
        "def analyze_sentiment(text):\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "    document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
        "    sentiment = client.analyze_sentiment(request={\"document\": document}).document_sentiment\n",
        "    return {\"score\": sentiment.score, \"magnitude\": sentiment.magnitude}\n",
        "\n",
        "# Main document review function\n",
        "def process_document():\n",
        "    try:\n",
        "        text = upload_and_extract_text()\n",
        "\n",
        "        print(\"\\n--- Summarized Text ---\")\n",
        "        summary = summarize_text(text)\n",
        "        print(summary)\n",
        "\n",
        "        # print(\"\\n--- Named Entities ---\")\n",
        "        # entities = extract_entities(text)\n",
        "        # for entity in entities:\n",
        "        #     print(f\"Entity: {entity[0]}, Type: {entity[1]}\")\n",
        "\n",
        "        # print(\"\\n--- Topics ---\")\n",
        "        # topics = topic_modeling(text)\n",
        "        # for topic in topics:\n",
        "        #     print(f\"Topic: {topic}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Run the document review process\n",
        "process_document()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "ZqXKeGEirjAw",
        "outputId": "b1ced6c5-e4b1-47f1-9cf1-f9c1a07a8d43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your document (PDF, DOCX, or TXT):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89b205ba-4f5d-4d8f-bcf2-9e2a74d7eab7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89b205ba-4f5d-4d8f-bcf2-9e2a74d7eab7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving OEM-CORES-Thermal-Stereo-Vision.pdf to OEM-CORES-Thermal-Stereo-Vision (4).pdf\n",
            "\n",
            "--- Summarized Text ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your min_length=50 must be inferior than your max_length=46.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autonomous vehicles must leverage a variety of sensor types fused together. These include visible cameras, radar, LIDAR, sonar and thermal imaging. Of these sensors, thermal imaging is particularly useful for helping a vehicle “see” in challenging weather and lighting conditions. The ability to make these vehicles truly autonomous anytime, anywhere, remains a technical challenge. Autonomous vehicles of the future must be able to determine, not simply guess, which areas are appropriate for moving vehicles, day or night. For instance, unmapped areas or places that don’t have lanes or include uncommon infrastructure and environmental features, still pose Thermal cameras detect and measure an entirely different wavelength of energy compared to other sensors, known as long-wave infrared (LWIR) radiation, or heat energy. This part of the electromagnetic spectrum radiates, absorbs, or is reflected by everything on Earth. Therefore, thermal cameras detect heat equally well in daylight Thermal imaging is also a passive technology. Unlike LIDAR, it does not send out and receive signals for object detection. It can create three-dimensional (3D) awareness of its surrounding environment and can also serve as a complementary and redundant system to LIDar. Thermal stereo vision works similar to human vision in that it’s based on triangulation of rays, in this case thermal rays, from two or possibly more viewpoints. It provides depth perception by computing distance to different objects in a given scene. This is achieved by finding corresponding pixels between the thermal stereo pair and triangulating the distance measurements Disparity refers to the difference in image location of an object observed in the stereo pair and a closer object has a larger disparity. Thermal stereo cameras are valuable for partial autonomous systems that already exist today, such as automatic emergency response systems. The thermal stereo camera theoretically tells the vehicle’s computer system to slow down upon detecting an object in the road in any lighting condition. It could also provide redundant distance data, along with the vehicle's visible camera\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}